{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTqsoUOY1dG",
        "outputId": "f0b80c65-71fa-4df4-97d3-14e04a4c75a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from time import perf_counter\n",
        "import os\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYu2_ryrY7CH",
        "outputId": "5a5ea210-6676-4b95-b9b3-eb845ce7fb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 670 files belonging to 3 classes.\n",
            "Using 503 files for training.\n",
            "Found 670 files belonging to 3 classes.\n",
            "Using 167 files for validation.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Defining batch specifications\n",
        "batch_size = 10\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "# Loading training data\n",
        "training_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Deep learning dataset/dataset 1',xz\n",
        "    validation_split=0.25,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True  # Set to True for better randomization\n",
        ")\n",
        "\n",
        "# Loading testing data\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Deep learning dataset/dataset 1',\n",
        "    validation_split=0.25,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMYmkRbFZRBk",
        "outputId": "72ad6823-2188-4f5e-e7f3-67d447245455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "Epoch 1/25\n",
            "51/51 [==============================] - 500s 9s/step - loss: 13.5983 - accuracy: 0.5268 - val_loss: 2.7313 - val_accuracy: 0.7246\n",
            "Epoch 2/25\n",
            "51/51 [==============================] - 469s 9s/step - loss: 1.1788 - accuracy: 0.8449 - val_loss: 1.8005 - val_accuracy: 0.7784\n",
            "Epoch 3/25\n",
            "51/51 [==============================] - 476s 9s/step - loss: 0.3195 - accuracy: 0.9483 - val_loss: 1.4803 - val_accuracy: 0.7844\n",
            "Epoch 4/25\n",
            "51/51 [==============================] - 473s 9s/step - loss: 0.3109 - accuracy: 0.9702 - val_loss: 1.4310 - val_accuracy: 0.7665\n",
            "Epoch 5/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.2371 - accuracy: 0.9761 - val_loss: 1.4439 - val_accuracy: 0.8084\n",
            "Epoch 6/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.1723 - accuracy: 0.9742 - val_loss: 1.3839 - val_accuracy: 0.7964\n",
            "Epoch 7/25\n",
            "51/51 [==============================] - 432s 8s/step - loss: 0.1282 - accuracy: 0.9761 - val_loss: 1.3417 - val_accuracy: 0.7964\n",
            "Epoch 8/25\n",
            "51/51 [==============================] - 464s 9s/step - loss: 0.1043 - accuracy: 0.9761 - val_loss: 1.4513 - val_accuracy: 0.8024\n",
            "Epoch 9/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.0994 - accuracy: 0.9742 - val_loss: 1.3550 - val_accuracy: 0.7964\n",
            "Epoch 10/25\n",
            "51/51 [==============================] - 466s 9s/step - loss: 0.0700 - accuracy: 0.9742 - val_loss: 1.2932 - val_accuracy: 0.7964\n",
            "Epoch 11/25\n",
            "51/51 [==============================] - 467s 9s/step - loss: 0.0373 - accuracy: 0.9761 - val_loss: 1.3181 - val_accuracy: 0.7904\n",
            "Epoch 12/25\n",
            "51/51 [==============================] - 468s 9s/step - loss: 0.0477 - accuracy: 0.9742 - val_loss: 1.3487 - val_accuracy: 0.7904\n",
            "Epoch 13/25\n",
            "51/51 [==============================] - 467s 9s/step - loss: 0.0355 - accuracy: 0.9722 - val_loss: 1.4010 - val_accuracy: 0.7844\n",
            "Epoch 14/25\n",
            "51/51 [==============================] - 431s 8s/step - loss: 0.0327 - accuracy: 0.9722 - val_loss: 1.5742 - val_accuracy: 0.7784\n",
            "Epoch 15/25\n",
            "51/51 [==============================] - 463s 9s/step - loss: 0.0556 - accuracy: 0.9742 - val_loss: 1.4133 - val_accuracy: 0.7784\n",
            "Epoch 16/25\n",
            "51/51 [==============================] - 432s 9s/step - loss: 0.0304 - accuracy: 0.9702 - val_loss: 1.6839 - val_accuracy: 0.7485\n",
            "Epoch 17/25\n",
            "51/51 [==============================] - 433s 8s/step - loss: 0.0514 - accuracy: 0.9722 - val_loss: 1.3683 - val_accuracy: 0.7964\n",
            "Epoch 18/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.0302 - accuracy: 0.9742 - val_loss: 1.3676 - val_accuracy: 0.7904\n",
            "Epoch 19/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.0364 - accuracy: 0.9742 - val_loss: 1.3813 - val_accuracy: 0.7964\n",
            "Epoch 20/25\n",
            "51/51 [==============================] - 465s 9s/step - loss: 0.0308 - accuracy: 0.9682 - val_loss: 1.3924 - val_accuracy: 0.7964\n",
            "Epoch 21/25\n",
            "51/51 [==============================] - 470s 9s/step - loss: 0.0300 - accuracy: 0.9742 - val_loss: 1.4096 - val_accuracy: 0.8024\n",
            "Epoch 22/25\n",
            "51/51 [==============================] - 468s 9s/step - loss: 0.0302 - accuracy: 0.9742 - val_loss: 1.4201 - val_accuracy: 0.8024\n",
            "Epoch 23/25\n",
            "51/51 [==============================] - 433s 9s/step - loss: 0.0300 - accuracy: 0.9801 - val_loss: 1.4279 - val_accuracy: 0.8024\n",
            "Epoch 24/25\n",
            "51/51 [==============================] - 435s 9s/step - loss: 0.0301 - accuracy: 0.9722 - val_loss: 1.4354 - val_accuracy: 0.8024\n",
            "Epoch 25/25\n",
            "51/51 [==============================] - 434s 9s/step - loss: 0.0302 - accuracy: 0.9722 - val_loss: 1.3884 - val_accuracy: 0.8084\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "# Preprocessing layers for VGG16\n",
        "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "\n",
        "# Creating the VGG16 base model\n",
        "base_model = VGG16(input_shape=(img_height, img_width, 3),\n",
        "                   include_top=False,\n",
        "                   weights='imagenet')\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Adding a custom classifier on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "x = preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = Flatten()(x)  # Flatten the output before connecting to fully connected layers\n",
        "x = Dense(256, activation='relu')(x)  # Add a dense layer for additional features\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Creating the final model\n",
        "vgg16_model = Model(inputs, outputs)\n",
        "\n",
        "# Compiling the model\n",
        "vgg16_model.compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = vgg16_model.fit(training_ds, validation_data=validation_ds, epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvwjMovxz8Vt",
        "outputId": "f4b078b8-413a-4015-cdec-95066be78355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 12.0774 - accuracy: 0.5765 - val_loss: 2.5155 - val_accuracy: 0.7066\n",
            "Epoch 2/20\n",
            "51/51 [==============================] - 322s 6s/step - loss: 0.7613 - accuracy: 0.8489 - val_loss: 1.1376 - val_accuracy: 0.7784\n",
            "Epoch 3/20\n",
            "51/51 [==============================] - 319s 6s/step - loss: 0.1779 - accuracy: 0.9563 - val_loss: 1.3665 - val_accuracy: 0.7665\n",
            "Epoch 4/20\n",
            "51/51 [==============================] - 323s 6s/step - loss: 0.1626 - accuracy: 0.9622 - val_loss: 1.0783 - val_accuracy: 0.7844\n",
            "Epoch 5/20\n",
            "51/51 [==============================] - 323s 6s/step - loss: 0.0576 - accuracy: 0.9742 - val_loss: 1.2714 - val_accuracy: 0.7784\n",
            "Epoch 6/20\n",
            "51/51 [==============================] - 321s 6s/step - loss: 0.0892 - accuracy: 0.9722 - val_loss: 1.0217 - val_accuracy: 0.7784\n",
            "Epoch 7/20\n",
            "51/51 [==============================] - 389s 8s/step - loss: 0.0662 - accuracy: 0.9742 - val_loss: 1.1405 - val_accuracy: 0.7784\n",
            "Epoch 8/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0724 - accuracy: 0.9742 - val_loss: 1.1153 - val_accuracy: 0.7784\n",
            "Epoch 9/20\n",
            "51/51 [==============================] - 319s 6s/step - loss: 0.0455 - accuracy: 0.9742 - val_loss: 1.1241 - val_accuracy: 0.7784\n",
            "Epoch 10/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0430 - accuracy: 0.9702 - val_loss: 1.2092 - val_accuracy: 0.7784\n",
            "Epoch 11/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0404 - accuracy: 0.9722 - val_loss: 1.1930 - val_accuracy: 0.7784\n",
            "Epoch 12/20\n",
            "51/51 [==============================] - 318s 6s/step - loss: 0.0501 - accuracy: 0.9702 - val_loss: 1.2477 - val_accuracy: 0.7665\n",
            "Epoch 13/20\n",
            "51/51 [==============================] - 321s 6s/step - loss: 0.0431 - accuracy: 0.9722 - val_loss: 1.2901 - val_accuracy: 0.7725\n",
            "Epoch 14/20\n",
            "51/51 [==============================] - 319s 6s/step - loss: 0.0645 - accuracy: 0.9702 - val_loss: 1.1424 - val_accuracy: 0.7725\n",
            "Epoch 15/20\n",
            "51/51 [==============================] - 323s 6s/step - loss: 0.0420 - accuracy: 0.9722 - val_loss: 1.1880 - val_accuracy: 0.7605\n",
            "Epoch 16/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0358 - accuracy: 0.9702 - val_loss: 1.2315 - val_accuracy: 0.7605\n",
            "Epoch 17/20\n",
            "51/51 [==============================] - 323s 6s/step - loss: 0.0548 - accuracy: 0.9722 - val_loss: 1.2307 - val_accuracy: 0.7605\n",
            "Epoch 18/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0467 - accuracy: 0.9722 - val_loss: 1.2579 - val_accuracy: 0.7605\n",
            "Epoch 19/20\n",
            "51/51 [==============================] - 320s 6s/step - loss: 0.0359 - accuracy: 0.9702 - val_loss: 1.2226 - val_accuracy: 0.7605\n",
            "Epoch 20/20\n",
            "51/51 [==============================] - 323s 6s/step - loss: 0.0346 - accuracy: 0.9682 - val_loss: 1.2156 - val_accuracy: 0.7545\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming img_height and img_width are predefined\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Preprocessing layers for VGG19\n",
        "preprocess_input = tf.keras.applications.vgg19.preprocess_input\n",
        "\n",
        "# Creating the VGG19 base model\n",
        "base_model = VGG19(input_shape=(img_height, img_width, 3),\n",
        "                   include_top=False,\n",
        "                   weights='imagenet')\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Adding a custom classifier on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "x = preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = Flatten()(x)  # Flatten the output before connecting to fully connected layers\n",
        "x = Dense(256, activation='relu')(x)  # Add a dense layer for additional features\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Creating the final model\n",
        "vgg19_model = Model(inputs, outputs)\n",
        "\n",
        "# Compiling the model\n",
        "vgg19_model.compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = vgg19_model.fit(training_ds, validation_data=validation_ds, epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkCeK0YR6BoI",
        "outputId": "094be5a7-6c2f-470b-a7fb-639c9f011d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "51/51 [==============================] - 141s 3s/step - loss: 0.8717 - accuracy: 0.6561 - val_loss: 0.5864 - val_accuracy: 0.7964\n",
            "Epoch 2/25\n",
            "51/51 [==============================] - 139s 3s/step - loss: 0.4278 - accuracy: 0.8410 - val_loss: 0.4478 - val_accuracy: 0.8323\n",
            "Epoch 3/25\n",
            "51/51 [==============================] - 133s 3s/step - loss: 0.3697 - accuracy: 0.8469 - val_loss: 0.5177 - val_accuracy: 0.7904\n",
            "Epoch 4/25\n",
            "51/51 [==============================] - 135s 3s/step - loss: 0.2342 - accuracy: 0.9205 - val_loss: 0.5861 - val_accuracy: 0.7844\n",
            "Epoch 5/25\n",
            "51/51 [==============================] - 133s 3s/step - loss: 0.2269 - accuracy: 0.9225 - val_loss: 0.6230 - val_accuracy: 0.8144\n",
            "Epoch 6/25\n",
            "51/51 [==============================] - 132s 3s/step - loss: 0.1648 - accuracy: 0.9483 - val_loss: 0.5636 - val_accuracy: 0.7725\n",
            "Epoch 7/25\n",
            "51/51 [==============================] - 120s 2s/step - loss: 0.1002 - accuracy: 0.9563 - val_loss: 0.6025 - val_accuracy: 0.7844\n",
            "Epoch 8/25\n",
            "51/51 [==============================] - 133s 3s/step - loss: 0.0930 - accuracy: 0.9682 - val_loss: 0.7244 - val_accuracy: 0.8204\n",
            "Epoch 9/25\n",
            "51/51 [==============================] - 136s 3s/step - loss: 0.1301 - accuracy: 0.9543 - val_loss: 0.6708 - val_accuracy: 0.7844\n",
            "Epoch 10/25\n",
            "51/51 [==============================] - 131s 3s/step - loss: 0.1014 - accuracy: 0.9702 - val_loss: 0.7616 - val_accuracy: 0.8084\n",
            "Epoch 11/25\n",
            "51/51 [==============================] - 119s 2s/step - loss: 0.1171 - accuracy: 0.9583 - val_loss: 0.8335 - val_accuracy: 0.7904\n",
            "Epoch 12/25\n",
            "51/51 [==============================] - 117s 2s/step - loss: 0.1152 - accuracy: 0.9662 - val_loss: 0.8018 - val_accuracy: 0.7485\n",
            "Epoch 13/25\n",
            "51/51 [==============================] - 123s 2s/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 0.6851 - val_accuracy: 0.8084\n",
            "Epoch 14/25\n",
            "51/51 [==============================] - 131s 3s/step - loss: 0.1071 - accuracy: 0.9642 - val_loss: 0.7594 - val_accuracy: 0.7605\n",
            "Epoch 15/25\n",
            "51/51 [==============================] - 131s 3s/step - loss: 0.0790 - accuracy: 0.9702 - val_loss: 0.7586 - val_accuracy: 0.8263\n",
            "Epoch 16/25\n",
            "51/51 [==============================] - 133s 3s/step - loss: 0.0896 - accuracy: 0.9682 - val_loss: 0.7643 - val_accuracy: 0.7665\n",
            "Epoch 17/25\n",
            "51/51 [==============================] - 130s 3s/step - loss: 0.0769 - accuracy: 0.9742 - val_loss: 0.7715 - val_accuracy: 0.8084\n",
            "Epoch 18/25\n",
            "51/51 [==============================] - 121s 2s/step - loss: 0.0832 - accuracy: 0.9722 - val_loss: 0.8109 - val_accuracy: 0.8084\n",
            "Epoch 19/25\n",
            "51/51 [==============================] - 122s 2s/step - loss: 0.0868 - accuracy: 0.9642 - val_loss: 0.8123 - val_accuracy: 0.7784\n",
            "Epoch 20/25\n",
            "51/51 [==============================] - 135s 3s/step - loss: 0.0820 - accuracy: 0.9682 - val_loss: 0.9031 - val_accuracy: 0.7485\n",
            "Epoch 21/25\n",
            "51/51 [==============================] - 130s 3s/step - loss: 0.0695 - accuracy: 0.9722 - val_loss: 0.8871 - val_accuracy: 0.7485\n",
            "Epoch 22/25\n",
            "51/51 [==============================] - 131s 3s/step - loss: 0.0855 - accuracy: 0.9742 - val_loss: 0.9566 - val_accuracy: 0.7725\n",
            "Epoch 23/25\n",
            "51/51 [==============================] - 119s 2s/step - loss: 0.0711 - accuracy: 0.9682 - val_loss: 0.7683 - val_accuracy: 0.8084\n",
            "Epoch 24/25\n",
            "51/51 [==============================] - 132s 3s/step - loss: 0.0672 - accuracy: 0.9722 - val_loss: 0.8509 - val_accuracy: 0.7605\n",
            "Epoch 25/25\n",
            "51/51 [==============================] - 131s 3s/step - loss: 0.0814 - accuracy: 0.9702 - val_loss: 0.9051 - val_accuracy: 0.7964\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing layers for ResNet50\n",
        "preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
        "# Creating the ResNet50 base model\n",
        "base_model = ResNet50(input_shape=(img_height, img_width, 3),\n",
        "                      include_top=False,\n",
        "                      weights='imagenet')\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Adding a custom classifier on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "x = preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)  # Use GlobalAveragePooling2D instead of Flatten\n",
        "x = Dense(256, activation='relu')(x)\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Creating the final model\n",
        "resnet50_model = Model(inputs, outputs)\n",
        "\n",
        "# Compiling the model\n",
        "resnet50_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = resnet50_model.fit(training_ds, validation_data=validation_ds, epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnXErODjKFJB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}